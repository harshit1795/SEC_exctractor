{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SEC EDGAR RESTful data APIs\n",
    "\n",
    "This notebook shows how to retrieve information reported by regulated entities to U.S. Securities and Exchange Commision (SEC).\n",
    "\n",
    "SEC is maintainig EDGAR system with information about all regulated enties (companies, funds, individuals). Accessing the data is free and there is number of [various ways how to access the data](https://www.sec.gov/os/accessing-edgar-data).\n",
    "\n",
    "\"data.sec.gov\" was created to host RESTful data Application Programming Interfaces (APIs) delivering JSON-formatted data to external customers and to web pages on SEC.gov. These APIs do not require any authentication or API keys to access.\n",
    "\n",
    "Currently included in the APIs are the submissions history by filer and the XBRL data from financial statements (forms 10-Q, 10-K,8-K, 20-F, 40-F, 6-K, and their variants).\n",
    "\n",
    "The JSON structures are updated throughout the day, in real time, as submissions are disseminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import boto3\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding CIK of company\n",
    "\n",
    "EDGAR assigns to filers a unique numerical identifier, known as a Central Index Key (CIK), when they sign up to make filings to the SEC. CIK numbers remain unique to the filer; they are not recycled. \n",
    "\n",
    "List of all CIKs matched with entity name is available for download [(13 MB, text file)](https://www.sec.gov/Archives/edgar/cik-lookup-data.txt). Note that this list includes funds and individuals and is historically cumulative for company names. Thus a given CIK may be associated with multiple names in the case of company or fund name changes, and the list contains some entities that no longer file with the SEC.\n",
    "\n",
    "We will be using smaller (611 kB) JSON [kaggle dataset](https://www.kaggle.com/datasets/svendaj/sec-edgar-cik-ticker-exchange), which is sourcing data directly at EDGAR and is input for this notebook. This dataset contains only companies names, CIK, ticker and associated stock exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's convert CIK JSON to pandas DataFrame\n",
    "# First load the data into python dictionary\n",
    "\n",
    "\n",
    "CIK_df=pd.read_json(\"company_tickers.json\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1652044</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045810</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cik_str ticker           title\n",
       "0   320193   AAPL      Apple Inc.\n",
       "1   789019   MSFT  MICROSOFT CORP\n",
       "2  1652044  GOOGL   Alphabet Inc.\n",
       "3  1018724   AMZN  AMAZON COM INC\n",
       "4  1045810   NVDA     NVIDIA CORP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIK_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIK_df.rename(columns={'cik_str': 'cik', 'title':'name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a particular company based upon the Name they are registered with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>101829</td>\n",
       "      <td>RTX</td>\n",
       "      <td>RAYTHEON TECHNOLOGIES CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>723125</td>\n",
       "      <td>MU</td>\n",
       "      <td>MICRON TECHNOLOGY INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1543151</td>\n",
       "      <td>UBER</td>\n",
       "      <td>Uber Technologies, Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1835632</td>\n",
       "      <td>MRVL</td>\n",
       "      <td>Marvell Technology, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>882835</td>\n",
       "      <td>ROP</td>\n",
       "      <td>ROPER TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9052</th>\n",
       "      <td>1855631</td>\n",
       "      <td>AWINW</td>\n",
       "      <td>AERWINS Technologies Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>1847416</td>\n",
       "      <td>ORIAW</td>\n",
       "      <td>Orion Biotech Opportunities Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>1872964</td>\n",
       "      <td>MTEKW</td>\n",
       "      <td>Maris Tech Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9197</th>\n",
       "      <td>1070050</td>\n",
       "      <td>APCXW</td>\n",
       "      <td>AppTech Payments Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>1084267</td>\n",
       "      <td>MOBQW</td>\n",
       "      <td>Mobiquity Technologies, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik ticker                               name\n",
       "69     101829    RTX         RAYTHEON TECHNOLOGIES CORP\n",
       "129    723125     MU              MICRON TECHNOLOGY INC\n",
       "136   1543151   UBER             Uber Technologies, Inc\n",
       "201   1835632   MRVL           Marvell Technology, Inc.\n",
       "233    882835    ROP             ROPER TECHNOLOGIES INC\n",
       "...       ...    ...                                ...\n",
       "9052  1855631  AWINW          AERWINS Technologies Inc.\n",
       "9071  1847416  ORIAW  Orion Biotech Opportunities Corp.\n",
       "9165  1872964  MTEKW                    Maris Tech Ltd.\n",
       "9197  1070050  APCXW             AppTech Payments Corp.\n",
       "9200  1084267  MOBQW       Mobiquity Technologies, Inc.\n",
       "\n",
       "[508 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding companies containing substring in company name\n",
    "substring = \"Tech\"\n",
    "CIK_df[CIK_df[\"name\"].str.contains(substring, case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entityâ€™s current filing history\n",
    "\n",
    "Each entityâ€™s current filing history is available at the following URL:\n",
    "\n",
    "* https://data.sec.gov/submissions/CIK##########.json\n",
    "\n",
    "Where the ########## is the entityâ€™s 10-digit Central Index Key (CIK), including leading zeros.\n",
    "\n",
    "This JSON data structure contains metadata such as current name, former name, and stock exchanges and ticker symbols of publicly-traded companies. The objectâ€™s property path contains at least one yearâ€™s of filing or to 1,000 (whichever is more) of the most recent filings in a compact columnar data array. If the entity has additional filings, files will contain an array of additional JSON files and the date range for the filings each one contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read response from REST API with `requests` library and format it as python dict\n",
    "\n",
    "import requests\n",
    "header_full = {\n",
    "    \"User-Agent\": \"harshit harshit.gola.off@gmail.com\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Host\": \"data.sec.gov\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "header = {\n",
    "    \"User-Agent\": \"harshit harshit.gola.off@gmail.com\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the ticker of company used in this example\n",
    "\n",
    "Subsequent information retrieval will be using selected `ticker` and associated CIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finding company row with given ticker\n",
    "\n",
    "def get_current_filing_history(url, header):\n",
    "    company_filings = requests.get(url, headers=header).json()\n",
    "    company_filings_df = pd.DataFrame(company_filings[\"filings\"][\"recent\"])\n",
    "    return company_filings_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from RESTful API\n",
    "\n",
    "EDGAR requires that HTTP requests will be identified with proper [UserAgent in header and comply with fair use policy (currently max. 10 requests per second)](https://www.sec.gov/os/accessing-edgar-data). At minimum you need to supply your own e-mail adress in User-Agent field (otherwise you will get 403/Forbiden error). If you will provide Host field, please be sure use data.sec.gov server and not www.sec.gov as mentioned in example (this would result in 404/Not Found error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrame with submitted filings\n",
    "\n",
    "`company_filings[\"filings\"][\"recent\"]` contains up to 1000 last submitted filings sorted from latest to oldest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_all_history(df, header):\n",
    "    df_=pd.DataFrame()\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        CIK = row['cik']\n",
    "        url = f\"https://data.sec.gov/submissions/CIK{str(CIK).zfill(10)}.json\"\n",
    "        company_filings_df = get_current_filing_history(url, header)\n",
    "        company_filings_df['ticker']=row['ticker']\n",
    "        company_filings_df['cik']=row['cik']\n",
    "        df_ = pd.concat([company_filings_df, df_])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b96ad4a6224e128b621e800ded3edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_history = pull_all_history(CIK_df[:100], header_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing specific filing document\n",
    "\n",
    "Let's download latest Annual Report (10-K). Files are stored in browsable directory structure for CIK and accession-number: \n",
    "* https://www.sec.gov/Archives/edgar/data/{CIK}/{accession-number}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Creating a function to create a url and run loop for all the items to download each of the filing htm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_all_forms(df, form, header):\n",
    "    df_ = df[df.form == form]\n",
    "    for index, row in tqdm(df_.iterrows(), total=df_.shape[0]):\n",
    "        url = f\"https://www.sec.gov/Archives/edgar/data/{row['cik']}/{row['accessionNumber'].replace('-', '')}/{row['primaryDocument']}\"\n",
    "        req_content = requests.get(url, headers=header).content.decode(\"utf-8\")\n",
    "        directory = f\"data/{row['ticker']}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        with open(f\"{directory}/{row['primaryDocument']}\", \"w\") as f:\n",
    "            f.write(req_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is to download all the 10K htm files for the 100 most recent filings into the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_all_forms(df_history, '10-K', header)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 10-K form\n",
    "# ## Business, Risk, and MD&A\n",
    "# The function *parse_10k_filing()* parses 10-K forms to extract the following sections: business description, business risk, and management discussioin and analysis. The function takes two arguments, a link and a number indicating the section, and returns a list with the requested sections. Current options are **0(All), 1(Business), 2(Risk), 4(MDA).**\n",
    "# \n",
    "# Caveats:\n",
    "# The function *parse_10k_filing()* is a parser. You need to feed a SEC text link into it. There are many python and r packages to get a direct link to the fillings.\n",
    "# \n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def parse_10k_filing(file_path, section):\n",
    "    \n",
    "    if section not in [0, 1, 2, 3]:\n",
    "        print(\"Not a valid section\")\n",
    "        sys.exit()\n",
    "    \n",
    "    def get_text(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        html = bs(content, 'html.parser')\n",
    "        text = html.get_text()\n",
    "        text = unicodedata.normalize(\"NFKD\", text).encode('ascii', 'ignore').decode('utf8')\n",
    "        text = text.split(\"\\n\")\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    \n",
    "    def extract_text(text, item_start, item_end):\n",
    "        item_start = item_start\n",
    "        item_end = item_end\n",
    "        starts = [i.start() for i in item_start.finditer(text)]\n",
    "        ends = [i.start() for i in item_end.finditer(text)]\n",
    "        positions = list()\n",
    "        for s in starts:\n",
    "            control = 0\n",
    "            for e in ends:\n",
    "                if control == 0:\n",
    "                    if s < e:\n",
    "                        control = 1\n",
    "                        positions.append([s,e])\n",
    "        item_length = 0\n",
    "        item_position = list()\n",
    "        for p in positions:\n",
    "            if (p[1]-p[0]) > item_length:\n",
    "                item_length = p[1]-p[0]\n",
    "                item_position = p\n",
    "\n",
    "        item_text = text[item_position[0]:item_position[1]]\n",
    "\n",
    "        return item_text\n",
    "\n",
    "    text = get_text(file_path)\n",
    "        \n",
    "    if section == 1 or section == 0:\n",
    "        try:\n",
    "            item1_start = re.compile(\"item\\s*[1][\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            item1_end = re.compile(\"item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk|item\\s*2[\\.\\,\\;\\:\\-\\_]\\s*Prop\", re.IGNORECASE)\n",
    "            businessText = extract_text(text, item1_start, item1_end)\n",
    "        except:\n",
    "            businessText = \"Something went wrong!\"\n",
    "        \n",
    "    if section == 2 or section == 0:\n",
    "        try:\n",
    "            item1a_start = re.compile(\"(?<!,\\s)item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk\", re.IGNORECASE)\n",
    "            item1a_end = re.compile(\"item\\s*2[\\.\\;\\:\\-\\_]\\s*Prop|item\\s*[1][\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            riskText = extract_text(text, item1a_start, item1a_end)\n",
    "        except:\n",
    "            riskText = \"Something went wrong!\"\n",
    "            \n",
    "    if section == 3 or section == 0:\n",
    "        try:\n",
    "            item7_start = re.compile(\"item\\s*[7][\\.\\;\\:\\-\\_]*\\s*\\\\bM\", re.IGNORECASE)\n",
    "            item7_end = re.compile(\"item\\s*7a[\\.\\;\\:\\-\\_]\\sQuanti|item\\s*8[\\.\\,\\;\\:\\-\\_]\\s*\", re.IGNORECASE)\n",
    "            mdaText = extract_text(text, item7_start, item7_end)\n",
    "        except:\n",
    "            mdaText = \"Something went wrong!\"\n",
    "    \n",
    "    if section == 0:\n",
    "        data = [businessText, riskText, mdaText]\n",
    "    elif section == 1:\n",
    "        data = [businessText]\n",
    "    elif section == 2:\n",
    "        data = [riskText]\n",
    "    elif section == 3:\n",
    "        data = [mdaText]\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_all_forms(df, form, header):\n",
    "    df_ = df[df.form == form]\n",
    "    df__ = pd.DataFrame()\n",
    "    for index, row in tqdm(df_.iterrows(), total=df_.shape[0]):\n",
    "        directory = f\"data/{row['ticker']}\"\n",
    "        file_path = 'data/AAPL/a10-k20179302017.htm'\n",
    "        section = 0\n",
    "        \n",
    "        # Parse the 10-K filing and store the results in a DataFrame\n",
    "        text_data = parse_10k_filing(file_path, section)\n",
    "        df_text = pd.DataFrame({'Text': text_data})\n",
    "        df_text['ticker'] = row['ticker']\n",
    "        df_text['filepath'] = file_path\n",
    "        df__ = pd.concat([df_text, df__])\n",
    "\n",
    "    return df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77420c8629f24e159aad2290b7ff55c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_text = parse_all_forms(df_history , '10-K', header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>ticker</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1610</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1611</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1612</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1613</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1614</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1614 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                               Text ticker   \n",
       "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
       "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
       "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
       "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
       "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
       "...    ...                                                ...    ...   \n",
       "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
       "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
       "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
       "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
       "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
       "\n",
       "                            filepath  \n",
       "0     data/AAPL/a10-k20179302017.htm  \n",
       "1     data/AAPL/a10-k20179302017.htm  \n",
       "2     data/AAPL/a10-k20179302017.htm  \n",
       "3     data/AAPL/a10-k20179302017.htm  \n",
       "4     data/AAPL/a10-k20179302017.htm  \n",
       "...                              ...  \n",
       "1609  data/AAPL/a10-k20179302017.htm  \n",
       "1610  data/AAPL/a10-k20179302017.htm  \n",
       "1611  data/AAPL/a10-k20179302017.htm  \n",
       "1612  data/AAPL/a10-k20179302017.htm  \n",
       "1613  data/AAPL/a10-k20179302017.htm  \n",
       "\n",
       "[1614 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the resulted dataframe in a csv format to AWS S3\n",
    "\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath  \n",
      "0     data/AAPL/a10-k20179302017.htm  \n",
      "1     data/AAPL/a10-k20179302017.htm  \n",
      "2     data/AAPL/a10-k20179302017.htm  \n",
      "3     data/AAPL/a10-k20179302017.htm  \n",
      "4     data/AAPL/a10-k20179302017.htm  \n",
      "...                              ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm  \n",
      "1610  data/AAPL/a10-k20179302017.htm  \n",
      "1611  data/AAPL/a10-k20179302017.htm  \n",
      "1612  data/AAPL/a10-k20179302017.htm  \n",
      "1613  data/AAPL/a10-k20179302017.htm  \n",
      "\n",
      "[1614 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Exporting the resulted dataframe in a csv format.\n",
    "\n",
    "file_path='./All Reports Data.csv'\n",
    "\n",
    "\n",
    "\n",
    "#Arranging the index and adding Id column\n",
    "df_text = df_text.reset_index(drop=True)\n",
    "df_text['Id'] = df_text.index+1\n",
    "\n",
    "# Pop the column from its current position\n",
    "new_column = df_text.pop('Id')\n",
    "\n",
    "# Insert the column at the front of the DataFrame\n",
    "df_text.insert(0, 'Id', new_column)\n",
    "\n",
    "print(df_text)\n",
    "df_text.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing the parse text for a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  Item 1. BusinessCompany BackgroundThe Company ...\n",
      "1  Item 1A. Risk FactorsThe following discussion ...\n",
      "2  Item 7. Managements Discussion and Analysis of...\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/AAPL/a10-k20179302017.htm'\n",
    "section = 0\n",
    "\n",
    "# Parse the 10-K filing and store the results in a DataFrame\n",
    "text_data = parse_10k_filing(file_path, section)\n",
    "df = pd.DataFrame({'Text': text_data})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath  \n",
      "0     data/AAPL/a10-k20179302017.htm  \n",
      "1     data/AAPL/a10-k20179302017.htm  \n",
      "2     data/AAPL/a10-k20179302017.htm  \n",
      "3     data/AAPL/a10-k20179302017.htm  \n",
      "4     data/AAPL/a10-k20179302017.htm  \n",
      "...                              ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm  \n",
      "1610  data/AAPL/a10-k20179302017.htm  \n",
      "1611  data/AAPL/a10-k20179302017.htm  \n",
      "1612  data/AAPL/a10-k20179302017.htm  \n",
      "1613  data/AAPL/a10-k20179302017.htm  \n",
      "\n",
      "[1614 rows x 4 columns]\n",
      "(1614, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_read = pd.read_csv('All Reports Data.csv')\n",
    "\n",
    "print(df_read)\n",
    "print(df_read.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code to put all the texts from the latest 10k in a single row to be used for doing further appropriate cleaning.\n",
    "### Mostly all the financial statements contains declarations and disclosures that are specific to their nature of work and Industry they are serving. So, this file can act as a source to perform some further data processing and cleaning that can be later used to map some of the internal processes that only the business is aware about. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Column for categorizing the Sections of the forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Text', 'ticker', 'filepath', 'Category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df_read.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath           Category  \n",
      "0     data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "1     data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "2     data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "3     data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "4     data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "...                              ...                ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "1610  data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "1611  data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "1612  data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "1613  data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "\n",
      "[1614 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def assign_category(df):\n",
    "    # Create a new column 'Category'\n",
    "    df['Category'] = ''\n",
    "\n",
    "    # Define the keywords and their corresponding categories\n",
    "    keywords = {\n",
    "        'Item 1.': 'Business Overview',\n",
    "        'Item 1A.': 'Risk Factors',\n",
    "        'Item 7.': 'MD&A'\n",
    "    }\n",
    "\n",
    "    # Iterate over each row\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Text']\n",
    "\n",
    "        # Check if the 'Text' column contains any of the keywords\n",
    "        for keyword, category in keywords.items():\n",
    "            if keyword in text:\n",
    "                df.at[index, 'Category'] = category\n",
    "                break\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# Assuming your input DataFrame is called 'df_read'\n",
    "\n",
    "# Assign categories based on keywords\n",
    "df_with_category = assign_category(df_read)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df_with_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Exporting the resulted dataframe in a csv format.\n",
    "\n",
    "file_path='./All Reports Data.csv'\n",
    "\n",
    "df_with_category.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'glue-sec-etl'  # Replace with your bucket name\n",
    "csv_file_key = 'All Reports Data.csv'  # Replace with your desired key for the CSV filenpm install -g npm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(csv_file_key, bucket_name, csv_file_key)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
