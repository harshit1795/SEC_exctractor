{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SEC EDGAR RESTful data APIs\n",
    "\n",
    "This notebook shows how to retrieve information reported by regulated entities to U.S. Securities and Exchange Commision (SEC).\n",
    "\n",
    "SEC is maintainig EDGAR system with information about all regulated enties (companies, funds, individuals). Accessing the data is free and there is number of [various ways how to access the data](https://www.sec.gov/os/accessing-edgar-data).\n",
    "\n",
    "\"data.sec.gov\" was created to host RESTful data Application Programming Interfaces (APIs) delivering JSON-formatted data to external customers and to web pages on SEC.gov. These APIs do not require any authentication or API keys to access.\n",
    "\n",
    "Currently included in the APIs are the submissions history by filer and the XBRL data from financial statements (forms 10-Q, 10-K,8-K, 20-F, 40-F, 6-K, and their variants).\n",
    "\n",
    "The JSON structures are updated throughout the day, in real time, as submissions are disseminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import boto3\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding CIK of company\n",
    "\n",
    "EDGAR assigns to filers a unique numerical identifier, known as a Central Index Key (CIK), when they sign up to make filings to the SEC. CIK numbers remain unique to the filer; they are not recycled. \n",
    "\n",
    "List of all CIKs matched with entity name is available for download [(13 MB, text file)](https://www.sec.gov/Archives/edgar/cik-lookup-data.txt). Note that this list includes funds and individuals and is historically cumulative for company names. Thus a given CIK may be associated with multiple names in the case of company or fund name changes, and the list contains some entities that no longer file with the SEC.\n",
    "\n",
    "We will be using smaller (611 kB) JSON [kaggle dataset](https://www.kaggle.com/datasets/svendaj/sec-edgar-cik-ticker-exchange), which is sourcing data directly at EDGAR and is input for this notebook. This dataset contains only companies names, CIK, ticker and associated stock exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's convert CIK JSON to pandas DataFrame\n",
    "# First load the data into python dictionary\n",
    "\n",
    "\n",
    "CIK_df=pd.read_json(\"/home/jupyter/SEC_exctractor/company_tickers.json\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1652044</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045810</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cik_str ticker           title\n",
       "0   320193   AAPL      Apple Inc.\n",
       "1   789019   MSFT  MICROSOFT CORP\n",
       "2  1652044  GOOGL   Alphabet Inc.\n",
       "3  1018724   AMZN  AMAZON COM INC\n",
       "4  1045810   NVDA     NVIDIA CORP"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIK_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIK_df.rename(columns={'cik_str': 'cik', 'title':'name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a particular company based upon the Name they are registered with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>101829</td>\n",
       "      <td>RTX</td>\n",
       "      <td>RAYTHEON TECHNOLOGIES CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>723125</td>\n",
       "      <td>MU</td>\n",
       "      <td>MICRON TECHNOLOGY INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1543151</td>\n",
       "      <td>UBER</td>\n",
       "      <td>Uber Technologies, Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1835632</td>\n",
       "      <td>MRVL</td>\n",
       "      <td>Marvell Technology, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>882835</td>\n",
       "      <td>ROP</td>\n",
       "      <td>ROPER TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9052</th>\n",
       "      <td>1855631</td>\n",
       "      <td>AWINW</td>\n",
       "      <td>AERWINS Technologies Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>1847416</td>\n",
       "      <td>ORIAW</td>\n",
       "      <td>Orion Biotech Opportunities Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>1872964</td>\n",
       "      <td>MTEKW</td>\n",
       "      <td>Maris Tech Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9197</th>\n",
       "      <td>1070050</td>\n",
       "      <td>APCXW</td>\n",
       "      <td>AppTech Payments Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>1084267</td>\n",
       "      <td>MOBQW</td>\n",
       "      <td>Mobiquity Technologies, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik ticker                               name\n",
       "69     101829    RTX         RAYTHEON TECHNOLOGIES CORP\n",
       "129    723125     MU              MICRON TECHNOLOGY INC\n",
       "136   1543151   UBER             Uber Technologies, Inc\n",
       "201   1835632   MRVL           Marvell Technology, Inc.\n",
       "233    882835    ROP             ROPER TECHNOLOGIES INC\n",
       "...       ...    ...                                ...\n",
       "9052  1855631  AWINW          AERWINS Technologies Inc.\n",
       "9071  1847416  ORIAW  Orion Biotech Opportunities Corp.\n",
       "9165  1872964  MTEKW                    Maris Tech Ltd.\n",
       "9197  1070050  APCXW             AppTech Payments Corp.\n",
       "9200  1084267  MOBQW       Mobiquity Technologies, Inc.\n",
       "\n",
       "[508 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding companies containing substring in company name\n",
    "substring = \"Tech\"\n",
    "CIK_df[CIK_df[\"name\"].str.contains(substring, case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity’s current filing history\n",
    "\n",
    "Each entity’s current filing history is available at the following URL:\n",
    "\n",
    "* https://data.sec.gov/submissions/CIK##########.json\n",
    "\n",
    "Where the ########## is the entity’s 10-digit Central Index Key (CIK), including leading zeros.\n",
    "\n",
    "This JSON data structure contains metadata such as current name, former name, and stock exchanges and ticker symbols of publicly-traded companies. The object’s property path contains at least one year’s of filing or to 1,000 (whichever is more) of the most recent filings in a compact columnar data array. If the entity has additional filings, files will contain an array of additional JSON files and the date range for the filings each one contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read response from REST API with `requests` library and format it as python dict\n",
    "\n",
    "import requests\n",
    "header_full = {\n",
    "    \"User-Agent\": \"harshit harshit.gola.off@gmail.com\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Host\": \"data.sec.gov\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "header = {\n",
    "    \"User-Agent\": \"harshit harshit.gola.off@gmail.com\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the ticker of company used in this example\n",
    "\n",
    "Subsequent information retrieval will be using selected `ticker` and associated CIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finding company row with given ticker\n",
    "\n",
    "def get_current_filing_history(url, header):\n",
    "    company_filings = requests.get(url, headers=header).json()\n",
    "    company_filings_df = pd.DataFrame(company_filings[\"filings\"][\"recent\"])\n",
    "    return company_filings_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from RESTful API\n",
    "\n",
    "EDGAR requires that HTTP requests will be identified with proper [UserAgent in header and comply with fair use policy (currently max. 10 requests per second)](https://www.sec.gov/os/accessing-edgar-data). At minimum you need to supply your own e-mail adress in User-Agent field (otherwise you will get 403/Forbiden error). If you will provide Host field, please be sure use data.sec.gov server and not www.sec.gov as mentioned in example (this would result in 404/Not Found error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrame with submitted filings\n",
    "\n",
    "`company_filings[\"filings\"][\"recent\"]` contains up to 1000 last submitted filings sorted from latest to oldest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_all_history(df, header):\n",
    "    df_=pd.DataFrame()\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        CIK = row['cik']\n",
    "        url = f\"https://data.sec.gov/submissions/CIK{str(CIK).zfill(10)}.json\"\n",
    "        company_filings_df = get_current_filing_history(url, header)\n",
    "        company_filings_df['ticker']=row['ticker']\n",
    "        company_filings_df['cik']=row['cik']\n",
    "        df_ = pd.concat([company_filings_df, df_])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee34a31a317942ee8f2f703e71d0b92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_history = pull_all_history(CIK_df[:100], header_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessionNumber</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>reportDate</th>\n",
       "      <th>acceptanceDateTime</th>\n",
       "      <th>act</th>\n",
       "      <th>form</th>\n",
       "      <th>fileNumber</th>\n",
       "      <th>filmNumber</th>\n",
       "      <th>items</th>\n",
       "      <th>core_type</th>\n",
       "      <th>size</th>\n",
       "      <th>isXBRL</th>\n",
       "      <th>isInlineXBRL</th>\n",
       "      <th>primaryDocument</th>\n",
       "      <th>primaryDocDescription</th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000018230-25-000009</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td></td>\n",
       "      <td>2025-02-14T09:38:46.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>IRANNOTICE</td>\n",
       "      <td>001-00768</td>\n",
       "      <td>25623988</td>\n",
       "      <td></td>\n",
       "      <td>IRANNOTICE</td>\n",
       "      <td>76041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>catirannotice-202410xk.htm</td>\n",
       "      <td>IRANNOTICE</td>\n",
       "      <td>CAT</td>\n",
       "      <td>18230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000018230-25-000008</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2025-02-14T09:36:30.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-K</td>\n",
       "      <td>001-00768</td>\n",
       "      <td>25623971</td>\n",
       "      <td></td>\n",
       "      <td>XBRL</td>\n",
       "      <td>33945394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat-20241231.htm</td>\n",
       "      <td>10-K</td>\n",
       "      <td>CAT</td>\n",
       "      <td>18230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001104659-25-012855</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>2025-02-13T14:41:51.000Z</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>8873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xslF345X05/tm255985-10_4seq1.xml</td>\n",
       "      <td>OWNERSHIP DOCUMENT</td>\n",
       "      <td>CAT</td>\n",
       "      <td>18230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001104659-25-012854</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>2025-02-13T14:40:49.000Z</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>6563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xslF345X05/tm255985-9_4seq1.xml</td>\n",
       "      <td>OWNERSHIP DOCUMENT</td>\n",
       "      <td>CAT</td>\n",
       "      <td>18230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001104659-25-012853</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>2025-02-13T14:39:50.000Z</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>6513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xslF345X05/tm255985-8_4seq1.xml</td>\n",
       "      <td>OWNERSHIP DOCUMENT</td>\n",
       "      <td>CAT</td>\n",
       "      <td>18230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accessionNumber  filingDate  reportDate        acceptanceDateTime act   \n",
       "0  0000018230-25-000009  2025-02-14              2025-02-14T09:38:46.000Z  34  \\\n",
       "1  0000018230-25-000008  2025-02-14  2024-12-31  2025-02-14T09:36:30.000Z  34   \n",
       "2  0001104659-25-012855  2025-02-13  2025-02-11  2025-02-13T14:41:51.000Z       \n",
       "3  0001104659-25-012854  2025-02-13  2025-02-11  2025-02-13T14:40:49.000Z       \n",
       "4  0001104659-25-012853  2025-02-13  2025-02-11  2025-02-13T14:39:50.000Z       \n",
       "\n",
       "         form fileNumber filmNumber items   core_type      size  isXBRL   \n",
       "0  IRANNOTICE  001-00768   25623988        IRANNOTICE     76041       0  \\\n",
       "1        10-K  001-00768   25623971              XBRL  33945394       1   \n",
       "2           4                                       4      8873       0   \n",
       "3           4                                       4      6563       0   \n",
       "4           4                                       4      6513       0   \n",
       "\n",
       "   isInlineXBRL                   primaryDocument primaryDocDescription   \n",
       "0             0        catirannotice-202410xk.htm            IRANNOTICE  \\\n",
       "1             1                  cat-20241231.htm                  10-K   \n",
       "2             0  xslF345X05/tm255985-10_4seq1.xml    OWNERSHIP DOCUMENT   \n",
       "3             0   xslF345X05/tm255985-9_4seq1.xml    OWNERSHIP DOCUMENT   \n",
       "4             0   xslF345X05/tm255985-8_4seq1.xml    OWNERSHIP DOCUMENT   \n",
       "\n",
       "  ticker    cik  \n",
       "0    CAT  18230  \n",
       "1    CAT  18230  \n",
       "2    CAT  18230  \n",
       "3    CAT  18230  \n",
       "4    CAT  18230  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.to_csv('/home/jupyter/SEC_exctractor/data/history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing specific filing document\n",
    "\n",
    "Let's download latest Annual Report (10-K). Files are stored in browsable directory structure for CIK and accession-number: \n",
    "* https://www.sec.gov/Archives/edgar/data/{CIK}/{accession-number}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Creating a function to create a url and run loop for all the items to download each of the filing htm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_all_forms(df, form, header):\n",
    "    df_ = df[df.form == form]\n",
    "    for index, row in tqdm(df_.iterrows(), total=df_.shape[0]):\n",
    "        url = f\"https://www.sec.gov/Archives/edgar/data/{row['cik']}/{row['accessionNumber'].replace('-', '')}/{row['primaryDocument']}\"\n",
    "        req_content = requests.get(url, headers=header).content.decode(\"utf-8\")\n",
    "        directory = f\"data/{row['ticker']}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        with open(f\"{directory}/{row['primaryDocument']}\", \"w\") as f:\n",
    "            f.write(req_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is to download all the 10K htm files for the 100 most recent filings into the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4fbd2e2b104d96b8a8d04ca4ec6f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_all_forms(df_history, '10-K', header)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 10-K form\n",
    "# ## Business, Risk, and MD&A\n",
    "# The function *parse_10k_filing()* parses 10-K forms to extract the following sections: business description, business risk, and management discussioin and analysis. The function takes two arguments, a link and a number indicating the section, and returns a list with the requested sections. Current options are **0(All), 1(Business), 2(Risk), 4(MDA).**\n",
    "# \n",
    "# Caveats:\n",
    "# The function *parse_10k_filing()* is a parser. You need to feed a SEC text link into it. There are many python and r packages to get a direct link to the fillings.\n",
    "# \n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def parse_10k_filing(file_path, section):\n",
    "    \n",
    "    if section not in [0, 1, 2, 3]:\n",
    "        print(\"Not a valid section\")\n",
    "        sys.exit()\n",
    "    \n",
    "    def get_text(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        html = bs(content, 'html.parser')\n",
    "        text = html.get_text()\n",
    "        text = unicodedata.normalize(\"NFKD\", text).encode('ascii', 'ignore').decode('utf8')\n",
    "        text = text.split(\"\\n\")\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    \n",
    "    def extract_text(text, item_start, item_end):\n",
    "        item_start = item_start\n",
    "        item_end = item_end\n",
    "        starts = [i.start() for i in item_start.finditer(text)]\n",
    "        ends = [i.start() for i in item_end.finditer(text)]\n",
    "        positions = list()\n",
    "        for s in starts:\n",
    "            control = 0\n",
    "            for e in ends:\n",
    "                if control == 0:\n",
    "                    if s < e:\n",
    "                        control = 1\n",
    "                        positions.append([s,e])\n",
    "        item_length = 0\n",
    "        item_position = list()\n",
    "        for p in positions:\n",
    "            if (p[1]-p[0]) > item_length:\n",
    "                item_length = p[1]-p[0]\n",
    "                item_position = p\n",
    "\n",
    "        item_text = text[item_position[0]:item_position[1]]\n",
    "\n",
    "        return item_text\n",
    "\n",
    "    text = get_text(file_path)\n",
    "        \n",
    "    if section == 1 or section == 0:\n",
    "        try:\n",
    "            item1_start = re.compile(\"item\\s*[1][\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            item1_end = re.compile(\"item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk|item\\s*2[\\.\\,\\;\\:\\-\\_]\\s*Prop\", re.IGNORECASE)\n",
    "            businessText = extract_text(text, item1_start, item1_end)\n",
    "        except:\n",
    "            businessText = \"Something went wrong!\"\n",
    "        \n",
    "    if section == 2 or section == 0:\n",
    "        try:\n",
    "            item1a_start = re.compile(\"(?<!,\\s)item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk\", re.IGNORECASE)\n",
    "            item1a_end = re.compile(\"item\\s*2[\\.\\;\\:\\-\\_]\\s*Prop|item\\s*[1][\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            riskText = extract_text(text, item1a_start, item1a_end)\n",
    "        except:\n",
    "            riskText = \"Something went wrong!\"\n",
    "            \n",
    "    if section == 3 or section == 0:\n",
    "        try:\n",
    "            item7_start = re.compile(\"item\\s*[7][\\.\\;\\:\\-\\_]*\\s*\\\\bM\", re.IGNORECASE)\n",
    "            item7_end = re.compile(\"item\\s*7a[\\.\\;\\:\\-\\_]\\sQuanti|item\\s*8[\\.\\,\\;\\:\\-\\_]\\s*\", re.IGNORECASE)\n",
    "            mdaText = extract_text(text, item7_start, item7_end)\n",
    "        except:\n",
    "            mdaText = \"Something went wrong!\"\n",
    "    \n",
    "    if section == 0:\n",
    "        data = [businessText, riskText, mdaText]\n",
    "    elif section == 1:\n",
    "        data = [businessText]\n",
    "    elif section == 2:\n",
    "        data = [riskText]\n",
    "    elif section == 3:\n",
    "        data = [mdaText]\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_all_forms(df, form, header):\n",
    "    df_ = df[df.form == form]\n",
    "    df__ = pd.DataFrame()\n",
    "    for index, row in tqdm(df_.iterrows(), total=df_.shape[0]):\n",
    "        directory = f\"data/{row['ticker']}\"\n",
    "        file_path = 'data/AAPL/a10-k20179302017.htm'\n",
    "        section = 0\n",
    "        \n",
    "        # Parse the 10-K filing and store the results in a DataFrame\n",
    "        text_data = parse_10k_filing(file_path, section)\n",
    "        df_text = pd.DataFrame({'Text': text_data})\n",
    "        df_text['ticker'] = row['ticker']\n",
    "        df_text['filepath'] = file_path\n",
    "        df__ = pd.concat([df_text, df__])\n",
    "\n",
    "    return df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f21e0509d19468a986c58be9500fb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_text \u001b[38;5;241m=\u001b[39m \u001b[43mparse_all_forms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_history\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10-K\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mparse_all_forms\u001b[0;34m(df, form, header)\u001b[0m\n\u001b[1;32m      7\u001b[0m section \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Parse the 10-K filing and store the results in a DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m text_data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_10k_filing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m df_text \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m: text_data})\n\u001b[1;32m     12\u001b[0m df_text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[18], line 56\u001b[0m, in \u001b[0;36mparse_10k_filing\u001b[0;34m(file_path, section)\u001b[0m\n\u001b[1;32m     52\u001b[0m     item_text \u001b[38;5;241m=\u001b[39m text[item_position[\u001b[38;5;241m0\u001b[39m]:item_position[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item_text\n\u001b[0;32m---> 56\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m section \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m section \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mparse_10k_filing.<locals>.get_text\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     24\u001b[0m     content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 25\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m text \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mget_text()\n\u001b[1;32m     27\u001b[0m text \u001b[38;5;241m=\u001b[39m unicodedata\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFKD\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserRejectedMarkup(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/html/parser.py:172\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    170\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m--> 172\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    174\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_comment(i)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/html/parser.py:420\u001b[0m, in \u001b[0;36mHTMLParser.parse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_data(rawdata[i:gtpos])\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cdata_mode()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:169\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_endtag\u001b[0;34m(self, name, check_already_closed)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle a closing tag, e.g. '</tag>'\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m:param name: A tag name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m   e.g. '<tag></tag>'.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m#print(\"END\", name)\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_already_closed \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# This is a redundant end tag for an empty-element tag.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# We've already called handle_endtag() for it, so just\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# check it off the list.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m#print(\"ALREADY CLOSED\", name)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element\u001b[38;5;241m.\u001b[39mremove(name)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_text = parse_all_forms(df_history , '10-K', header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>ticker</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1610</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1611</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1612</td>\n",
       "      <td>Item 1. BusinessCompany BackgroundThe Company ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1613</td>\n",
       "      <td>Item 1A. Risk FactorsThe following discussion ...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1614</td>\n",
       "      <td>Item 7. Managements Discussion and Analysis of...</td>\n",
       "      <td>CAT</td>\n",
       "      <td>data/AAPL/a10-k20179302017.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1614 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                               Text ticker   \n",
       "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
       "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
       "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
       "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
       "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
       "...    ...                                                ...    ...   \n",
       "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
       "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
       "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
       "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
       "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
       "\n",
       "                            filepath  \n",
       "0     data/AAPL/a10-k20179302017.htm  \n",
       "1     data/AAPL/a10-k20179302017.htm  \n",
       "2     data/AAPL/a10-k20179302017.htm  \n",
       "3     data/AAPL/a10-k20179302017.htm  \n",
       "4     data/AAPL/a10-k20179302017.htm  \n",
       "...                              ...  \n",
       "1609  data/AAPL/a10-k20179302017.htm  \n",
       "1610  data/AAPL/a10-k20179302017.htm  \n",
       "1611  data/AAPL/a10-k20179302017.htm  \n",
       "1612  data/AAPL/a10-k20179302017.htm  \n",
       "1613  data/AAPL/a10-k20179302017.htm  \n",
       "\n",
       "[1614 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the resulted dataframe in a csv format to AWS S3\n",
    "\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath  \n",
      "0     data/AAPL/a10-k20179302017.htm  \n",
      "1     data/AAPL/a10-k20179302017.htm  \n",
      "2     data/AAPL/a10-k20179302017.htm  \n",
      "3     data/AAPL/a10-k20179302017.htm  \n",
      "4     data/AAPL/a10-k20179302017.htm  \n",
      "...                              ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm  \n",
      "1610  data/AAPL/a10-k20179302017.htm  \n",
      "1611  data/AAPL/a10-k20179302017.htm  \n",
      "1612  data/AAPL/a10-k20179302017.htm  \n",
      "1613  data/AAPL/a10-k20179302017.htm  \n",
      "\n",
      "[1614 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Exporting the resulted dataframe in a csv format.\n",
    "\n",
    "file_path='./All Reports Data.csv'\n",
    "\n",
    "\n",
    "\n",
    "#Arranging the index and adding Id column\n",
    "df_text = df_text.reset_index(drop=True)\n",
    "df_text['Id'] = df_text.index+1\n",
    "\n",
    "# Pop the column from its current position\n",
    "new_column = df_text.pop('Id')\n",
    "\n",
    "# Insert the column at the front of the DataFrame\n",
    "df_text.insert(0, 'Id', new_column)\n",
    "\n",
    "print(df_text)\n",
    "df_text.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing the parse text for a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  Item 1. BusinessCompany BackgroundThe Company ...\n",
      "1  Item 1A. Risk FactorsThe following discussion ...\n",
      "2  Item 7. Managements Discussion and Analysis of...\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/AAPL/a10-k20179302017.htm'\n",
    "section = 0\n",
    "\n",
    "# Parse the 10-K filing and store the results in a DataFrame\n",
    "text_data = parse_10k_filing(file_path, section)\n",
    "df = pd.DataFrame({'Text': text_data})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath  \n",
      "0     data/AAPL/a10-k20179302017.htm  \n",
      "1     data/AAPL/a10-k20179302017.htm  \n",
      "2     data/AAPL/a10-k20179302017.htm  \n",
      "3     data/AAPL/a10-k20179302017.htm  \n",
      "4     data/AAPL/a10-k20179302017.htm  \n",
      "...                              ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm  \n",
      "1610  data/AAPL/a10-k20179302017.htm  \n",
      "1611  data/AAPL/a10-k20179302017.htm  \n",
      "1612  data/AAPL/a10-k20179302017.htm  \n",
      "1613  data/AAPL/a10-k20179302017.htm  \n",
      "\n",
      "[1614 rows x 4 columns]\n",
      "(1614, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_read = pd.read_csv('All Reports Data.csv')\n",
    "\n",
    "print(df_read)\n",
    "print(df_read.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code to put all the texts from the latest 10k in a single row to be used for doing further appropriate cleaning.\n",
    "### Mostly all the financial statements contains declarations and disclosures that are specific to their nature of work and Industry they are serving. So, this file can act as a source to perform some further data processing and cleaning that can be later used to map some of the internal processes that only the business is aware about. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Column for categorizing the Sections of the forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Text', 'ticker', 'filepath', 'Category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df_read.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                               Text ticker   \n",
      "0        1  Item 1. BusinessCompany BackgroundThe Company ...   AAPL  \\\n",
      "1        2  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "2        3  Item 7. Managements Discussion and Analysis of...   AAPL   \n",
      "3        4  Item 1. BusinessCompany BackgroundThe Company ...   AAPL   \n",
      "4        5  Item 1A. Risk FactorsThe following discussion ...   AAPL   \n",
      "...    ...                                                ...    ...   \n",
      "1609  1610  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1610  1611  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "1611  1612  Item 1. BusinessCompany BackgroundThe Company ...    CAT   \n",
      "1612  1613  Item 1A. Risk FactorsThe following discussion ...    CAT   \n",
      "1613  1614  Item 7. Managements Discussion and Analysis of...    CAT   \n",
      "\n",
      "                            filepath           Category  \n",
      "0     data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "1     data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "2     data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "3     data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "4     data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "...                              ...                ...  \n",
      "1609  data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "1610  data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "1611  data/AAPL/a10-k20179302017.htm  Business Overview  \n",
      "1612  data/AAPL/a10-k20179302017.htm       Risk Factors  \n",
      "1613  data/AAPL/a10-k20179302017.htm               MD&A  \n",
      "\n",
      "[1614 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def assign_category(df):\n",
    "    # Create a new column 'Category'\n",
    "    df['Category'] = ''\n",
    "\n",
    "    # Define the keywords and their corresponding categories\n",
    "    keywords = {\n",
    "        'Item 1.': 'Business Overview',\n",
    "        'Item 1A.': 'Risk Factors',\n",
    "        'Item 7.': 'MD&A'\n",
    "    }\n",
    "\n",
    "    # Iterate over each row\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Text']\n",
    "\n",
    "        # Check if the 'Text' column contains any of the keywords\n",
    "        for keyword, category in keywords.items():\n",
    "            if keyword in text:\n",
    "                df.at[index, 'Category'] = category\n",
    "                break\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# Assuming your input DataFrame is called 'df_read'\n",
    "\n",
    "# Assign categories based on keywords\n",
    "df_with_category = assign_category(df_read)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df_with_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Exporting the resulted dataframe in a csv format.\n",
    "\n",
    "file_path='./All Reports Data.csv'\n",
    "\n",
    "df_with_category.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'glue-sec-etl'  # Replace with your bucket name\n",
    "csv_file_key = 'All Reports Data.csv'  # Replace with your desired key for the CSV filenpm install -g npm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(csv_file_key, bucket_name, csv_file_key)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
